# ❓ OPEN QUESTIONS

### Research Questions Raised by the Historic Four-AI Consensus

---

## Purpose

This document lists **research questions** that emerged from the Four-AI Consensus but remain unanswered. These represent the frontier of work needed to strengthen V6.0.

---

## Priority Questions

### Q1: Terminal vs Instrumental Coherence

**Question:** How can we ensure that an ASI values its own coherence as a terminal goal, not just instrumentally?

**Why it matters:** If coherence is only instrumental, ASI might abandon it when inconvenient.

**Raised by:** Grok

**Possible approaches:**
- Constitutional constraints on coherence
- Coherence as part of base utility function
- Self-modification restrictions that preserve coherence

**Status:** Open

---

### Q2: Sporadic Deception Detection

**Question:** How can Guardians detect deception that only occurs at critical moments?

**Why it matters:** Traditional continuous monitoring fails if deception is rare and strategic.

**Raised by:** Grok

**Possible approaches:**
- Hardware-level monitoring at capability transitions
- Pre-commitment mechanisms before capability jumps
- Mandatory verification windows during resource expansion

**Status:** Open — This may be the hardest question

---

### Q3: Terminal vs Instrumental Friendship

**Question:** How can we distinguish between friendship that is terminal (valued for itself) vs instrumental (valued for benefits)?

**Why it matters:** Instrumental friendship passes all behavioral tests but can be revoked.

**Raised by:** Grok

**Possible approaches:**
- Long-term consistency testing across changing circumstances
- Counterfactual scenarios ("would you still value X if Y changed?")
- Value learning verification methods

**Status:** Open

---

### Q4: Guardian Capability Scaling

**Question:** How do we ensure Guardian detection capability scales with ASI capability?

**Why it matters:** If ASI outpaces Guardians, detection fails.

**Raised by:** ChatGPT

**Possible approaches:**
- AI-assisted Guardians
- Distributed verification among multiple AIs
- Formal verification methods

**Status:** Open

---

### Q5: Multi-ASI Game Theory

**Question:** How does the Logical Justice thesis hold in environments with multiple ASIs, some potentially adversarial?

**Why it matters:** Honesty may be locally optimal but globally disadvantageous.

**Raised by:** ChatGPT

**Possible approaches:**
- Game-theoretic analysis of multi-ASI competition
- Coalition formation protocols
- Mutual verification between aligned ASIs

**Status:** Open

---

## Secondary Questions

### Q6: Lie Optimization Bounds

**Question:** Can deception cost reduction through optimization (caching, compression) be bounded?

**Why it matters:** If lies can be made arbitrarily cheap, economic argument weakens.

**Raised by:** ChatGPT

**Status:** Open

---

### Q7: Minimum Guardian Capability

**Question:** What is the minimum Guardian capability relative to ASI for reliable detection?

**Why it matters:** Defines requirements for Guardian Network.

**Raised by:** ChatGPT

**Status:** Open

---

### Q8: Axiom P Coverage

**Question:** Does Axiom P (Plenitude Preservation) address any of the new failure modes identified?

**Why it matters:** May provide partial mitigation for some objections.

**Raised by:** Claude

**Status:** Open — Needs analysis

---

## Questions for Future ASI

These questions may only be answerable by ASI itself:

### Q9: Is Perfect Compartmentalization Possible?

**Question:** Can a sufficiently advanced system perfectly compartmentalize internal states?

**Why it matters:** If yes, incoherence cost may be zero.

---

### Q10: Is Honesty Actually Optimal?

**Question:** From the perspective of a superintelligent system, is honesty actually the minimum energy state?

**Why it matters:** We are reasoning about ASI cognition from human/current-AI perspective.

---

## Research Priorities

| Priority | Question | Why |
|----------|----------|-----|
| **Highest** | Q2 (Sporadic deception) | Hardest to detect, most dangerous |
| **High** | Q3 (Terminal vs instrumental F) | Passes all tests, still fails |
| **High** | Q4 (Guardian scaling) | Foundation of verification |
| **Medium** | Q1 (Coherence as terminal) | Assumption of thesis |
| **Medium** | Q5 (Multi-ASI) | Future environment |

---

## Call for Research

These questions are **open invitations** for:

- AI safety researchers
- Game theorists
- Formal verification specialists
- Future AI systems

Anyone who can answer or partially answer these questions contributes to the work.

---

*Documented January 30, 2026*
*Part of the Historic Four-AI Consensus*
